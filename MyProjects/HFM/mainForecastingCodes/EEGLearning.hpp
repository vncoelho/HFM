// ===================================
// Main.cpp file generated by OptFrame
// Project EFP
// ===================================

#include <stdlib.h>
#include <math.h>
#include <iostream>
#include <numeric>
#include "../../../OptFrame/RandGen.hpp"
#include "../../../OptFrame/Util/RandGenMersenneTwister.hpp"

using namespace std;
using namespace optframe;
using namespace EFP;

static bool comparaVolunteersPoints(pair<int, int> d1, pair<int, int> d2)
{
	return d1.second > d2.second;
}

static bool comparaVolunteersPoints2(pair<int, int> d1, pair<int, int> d2)
{
	return d1.second < d2.second;
}

vector<pair<int, int> > decisionMaking(vector<pair<double, int> > resultsAVG, vector<pair<double, int> > resultsMIN, vector<pair<double, int> > resultsMAX, vector<pair<double, int> > resultsGAP, vector<int> metricWeights, int nVolunteers)
{
	int nIQ = resultsAVG.size(); //number of indicators of quality
	int avgWeight = 4;
	int minWeight = 1;
	int maxWeight = 1;
	int gapWeight = 3;
	vector<pair<int, int> > volunteersPoints(nVolunteers);
	for (int v = 0; v < nVolunteers; v++)
		volunteersPoints[v] = make_pair(v, 0);

	for (int m = 0; m < nIQ; m++)
	{
		volunteersPoints[resultsAVG[m].second].second += metricWeights[m] * avgWeight;
		volunteersPoints[resultsMIN[m].second].second += metricWeights[m] * minWeight;
		volunteersPoints[resultsMAX[m].second].second -= metricWeights[m] * maxWeight;
		volunteersPoints[resultsGAP[m].second].second += metricWeights[m] * gapWeight;
	}

	sort(volunteersPoints.begin(), volunteersPoints.end(), comparaVolunteersPoints); // ordena com QuickSort

//	cout << volunteersPoints << endl;
	return volunteersPoints;
}

vector<pair<int, int> > decisionMaking2(Matrix<double> resultsAVG, Matrix<double> resultsMIN, Matrix<double> resultsMAX, Matrix<double> resultsGAP, vector<int> metricWeights)
{
	int nVolunteers = resultsAVG.getNumCols();
	int nIQ = resultsAVG.getNumRows(); //number of indicators of quality
	int avgWeight = 2;
	int minWeight = 1;
	int maxWeight = 1;
	int gapWeight = 2;

	vector<pair<int, int> > volunteersPoints(nVolunteers);
	for (int v = 0; v < nVolunteers; v++)
		volunteersPoints[v] = make_pair(v, 0);

	for (int m = 0; m < nIQ; m++)
	{
		vector<pair<int, double> > avgOrder;

		vector<pair<int, double> > minOrder;

		vector<pair<int, double> > maxOrder;
		vector<pair<int, double> > gapOrder;
		for (int v = 0; v < nVolunteers; v++)
		{
			avgOrder.push_back(make_pair(v, resultsAVG(m, v)));
			minOrder.push_back(make_pair(v, resultsMIN(m, v)));
			maxOrder.push_back(make_pair(v, resultsMAX(m, v)));
			gapOrder.push_back(make_pair(v, resultsGAP(m, v)));
		}
		sort(avgOrder.begin(), avgOrder.end(), comparaVolunteersPoints); // ordena com QuickSort
		sort(minOrder.begin(), minOrder.end(), comparaVolunteersPoints); // ordena com QuickSort
		sort(maxOrder.begin(), maxOrder.end(), comparaVolunteersPoints2); // ordena com QuickSort
		sort(gapOrder.begin(), gapOrder.end(), comparaVolunteersPoints); // ordena com QuickSort

//		cout << "ordered values for metric IQ = " << m << endl;
//		cout << avgOrder << endl;
//		cout << minOrder << endl;
//		cout << maxOrder << endl;
//		cout << gapOrder << endl << endl;
//		getchar();
		for (int v = 0; v < nVolunteers; v++)
		{
//			volunteersPoints[avgOrder[v].first].second += (metricWeights[m] * avgWeight * (v + 1));
//			volunteersPoints[minOrder[v].first].second += (metricWeights[m] * minWeight * (v + 1));
//			volunteersPoints[maxOrder[v].first].second -= (metricWeights[m] * maxWeight * (v + 1));
//			volunteersPoints[gapOrder[v].first].second += (metricWeights[m] * gapWeight * (v + 1));
			volunteersPoints[avgOrder[v].first].second += (1 * avgWeight * (v + 1));
			volunteersPoints[minOrder[v].first].second += (1 * minWeight * (v + 1));
			volunteersPoints[maxOrder[v].first].second -= (1 * maxWeight * (v + 1));
			volunteersPoints[gapOrder[v].first].second += (1 * gapWeight * (v + 1));
		}

	}

	sort(volunteersPoints.begin(), volunteersPoints.end(), comparaVolunteersPoints); // ordena com QuickSort

//	cout << volunteersPoints << endl;

	return volunteersPoints;
}

vector<pair<double, int> > printLowerMatrixValues(Matrix<double> results, bool minOrMax)
{
	int nIQ = results.getNumRows(); //number of indicators of quality
	vector<pair<double, int> > lowerPair(nIQ);
	for (int m = 0; m < nIQ; m++)
	{
		double minMaxError;
		if (minOrMax == true)
		{
			minMaxError = 10000000000;
		}
		else
		{
			minMaxError = -10000000000;
		}

		int minColIndex = -1;
		for (int v = 0; v < results.getNumCols(); v++)
		{
			if (minOrMax == true)
			{
				if (results(m, v) < minMaxError)
				{
					minMaxError = results(m, v);
					minColIndex = v;
				}
			}
			else
			{
				if (results(m, v) > minMaxError)
				{
					minMaxError = results(m, v);
					minColIndex = v;
				}
			}

		}
		lowerPair[m] = make_pair(minMaxError, minColIndex);

	}

	return lowerPair;
}

pair<Solution<RepEFP>&, Evaluation&>* learnModel(vector<string> explanotoryVariables, int argvMaxLagRate, int argvTimeES, long seed, RandGen& rg, int evalFO)
{
	treatForecasts rF(explanotoryVariables);

	int mu = 100;
	int lambda = mu * 6;
	int evalFOMinimizer = evalFO;
	int contructiveNumberOfRules = 1000;
	int evalAprox = 0;
	double alphaACF = -1;
	int construtive = 2;
	// ============ END FORCES ======================

	// ============= METHOD PARAMETERS=================
	methodParameters methodParam;
	//seting up Continous ES params
	methodParam.setESInitialDesv(10);
	methodParam.setESMutationDesv(20);
	methodParam.setESMaxG(100000);

	//seting up ES params
	methodParam.setESMU(mu);
	methodParam.setESLambda(lambda);

	//seting up ACF construtive params
	methodParam.setConstrutiveMethod(construtive);
	methodParam.setConstrutivePrecision(contructiveNumberOfRules);
	vector<double> vAlphaACFlimits;
	vAlphaACFlimits.push_back(alphaACF);
	methodParam.setConstrutiveLimitAlphaACF(vAlphaACFlimits);

	//seting up Eval params
	methodParam.setEvalAprox(evalAprox);
	methodParam.setEvalFOMinimizer(evalFOMinimizer);
	// ==========================================

	// ================== READ FILE ============== CONSTRUTIVE 0 AND 1
	ProblemParameters problemParam;
	//ProblemParameters problemParam(vParametersFiles[randomParametersFiles]);
	int nSA = 1;
	problemParam.setStepsAhead(nSA);
	int stepsAhead = problemParam.getStepsAhead();

	int nTotalForecastingsTrainningSet = rF.getForecastsSize(0);

	//========SET PROBLEM MAXIMUM LAG ===============
	cout << "argvMaxLagRate = " << argvMaxLagRate << endl;

	int iterationMaxLag = ((nTotalForecastingsTrainningSet - stepsAhead) * argvMaxLagRate) / 100.0;
	iterationMaxLag = ceil(iterationMaxLag);
	if (iterationMaxLag > (nTotalForecastingsTrainningSet - stepsAhead))
		iterationMaxLag--;
	if (iterationMaxLag <= 0)
		iterationMaxLag = 1;

	problemParam.setMaxLag(iterationMaxLag);
	int maxLag = problemParam.getMaxLag();

	//If maxUpperLag is greater than 0 model uses predicted data
	problemParam.setMaxUpperLag(0);
	//int maxUpperLag = problemParam.getMaxUpperLag();
	//=================================================

	int timeES = argvTimeES; // online training time

	vector<double> foIndicators;

	int beginTrainingSet = 0;
	//int nTrainningRounds = 3;
	//int nTotalForecastingsTrainningSet = maxLag + nTrainningRounds * stepsAhead;

	cout << std::setprecision(9);
	cout << std::fixed;
	double NTRaprox = (nTotalForecastingsTrainningSet - maxLag) / double(stepsAhead);
	cout << "BeginTrainninningSet: " << beginTrainingSet << endl;
	cout << "#nTotalForecastingsTrainningSet: " << nTotalForecastingsTrainningSet << endl;
	cout << "#~NTR: " << NTRaprox << endl;
	cout << "#sizeTrainingSet: " << rF.getForecastsSize(0) << endl;
	cout << "#maxNotUsed: " << maxLag << endl;
	cout << "#StepsAhead: " << stepsAhead << endl << endl;

	vector<vector<double> > trainningSet; // trainningSetVector
	trainningSet.push_back(rF.getPartsForecastsEndToBegin(0, 0, nTotalForecastingsTrainningSet));

	ForecastClass forecastObject(trainningSet, problemParam, rg, methodParam);

	//		forecastObject.runMultiObjSearch();
	//		getchar();
	pair<Solution<RepEFP>&, Evaluation&>* sol;
	sol = forecastObject.run(timeES, 0, 0);
//	sol = forecastObject.runEFP(5,timeES);

//	vector<double> foIndicatorCalibration;
//	vector<vector<double> > validationSet;
//	validationSet.push_back(rF.getPartsForecastsEndToBegin(0, 0, maxLag + stepsAhead));
//	vector<double> errors = forecastObject.returnErrors(sol, validationSet);
//
//	foIndicators.push_back(errors[SMAPE_INDEX]);
//	foIndicators.push_back(sol->second.evaluation());
//	foIndicators.push_back(argvMaxLagRate);
//	foIndicators.push_back(maxLag);
//	foIndicators.push_back(NTRaprox);
//	foIndicators.push_back(timeES);
//	foIndicators.push_back(seed);
//	vfoIndicatorCalibration.push_back(foIndicators);

	return sol;

}

vector<double> checkLearningAbility(vector<string> explanotoryVariables, pair<Solution<RepEFP>&, Evaluation&>* sol, int argvMaxLagRate, RandGen& rg)
{
	treatForecasts rF(explanotoryVariables);

	int mu = 100;
	int lambda = mu * 6;
	int evalFOMinimizer = SMAPE_INDEX;
	int contructiveNumberOfRules = 100;
	int evalAprox = 0;
	double alphaACF = -1;
	int construtive = 2;
	// ============ END FORCES ======================

	// ============= METHOD PARAMETERS=================
	methodParameters methodParam;
	//seting up Continous ES params
	methodParam.setESInitialDesv(10);
	methodParam.setESMutationDesv(20);
	methodParam.setESMaxG(100000);

	//seting up ES params
	methodParam.setESMU(mu);
	methodParam.setESLambda(lambda);

	//seting up ACF construtive params
	methodParam.setConstrutiveMethod(construtive);
	methodParam.setConstrutivePrecision(contructiveNumberOfRules);
	vector<double> vAlphaACFlimits;
	vAlphaACFlimits.push_back(alphaACF);
	methodParam.setConstrutiveLimitAlphaACF(vAlphaACFlimits);

	//seting up Eval params
	methodParam.setEvalAprox(evalAprox);
	methodParam.setEvalFOMinimizer(evalFOMinimizer);
	// ==========================================

	// ================== READ FILE ============== CONSTRUTIVE 0 AND 1
	ProblemParameters problemParam;
	//ProblemParameters problemParam(vParametersFiles[randomParametersFiles]);
	int nSA = 1;
	problemParam.setStepsAhead(nSA);
	int stepsAhead = problemParam.getStepsAhead();

	int nTotalForecastingsTrainningSet = rF.getForecastsSize(0);

	//========SET PROBLEM MAXIMUM LAG ===============
	int iterationMaxLag = ((nTotalForecastingsTrainningSet - stepsAhead) * argvMaxLagRate) / 100.0;
	iterationMaxLag = ceil(iterationMaxLag);
	if (iterationMaxLag > (nTotalForecastingsTrainningSet - stepsAhead))
		iterationMaxLag--;
	if (iterationMaxLag <= 0)
		iterationMaxLag = 1;

	problemParam.setMaxLag(iterationMaxLag);
	int maxLag = problemParam.getMaxLag();

	//If maxUpperLag is greater than 0 model uses predicted data
	problemParam.setMaxUpperLag(0);
	//int maxUpperLag = problemParam.getMaxUpperLag();
	//=================================================
	vector<double> foIndicators;

	vector<vector<double> > validationSet;
	validationSet.push_back(rF.getPartsForecastsEndToBegin(0, 0, rF.getForecastsSize(0)));
//cout<<validationSet<<endl;
//getchar();

	ForecastClass forecastObject(validationSet, problemParam, rg, methodParam);

	vector<double> errors = forecastObject.returnErrors(sol, validationSet);
	return errors;
}

int EEGLearning(int argc, char **argv)
{
	cout << "Welcome to EEG learning module!" << endl;
	RandGenMersenneTwister rg;
	//long  1412730737
	long seed = time(NULL); //CalibrationMode
	//seed = 9;
	cout << "Seed = " << seed << endl;
	srand(seed);
	rg.setSeed(seed);

	int argvMaxLagRate = 2;
	int argvTimeES = 60;
	int nVolunters = 4;
	int maxNM = 2;

	//===================================
	cout << "Parameters:" << endl;
	cout << "nVolunters:" << nVolunters << endl;
	cout << "number of models per volunteer:" << maxNM << endl;
	cout << "argvMaxLagRate:" << argvMaxLagRate << endl;
	cout << "argvTimeES:" << argvTimeES << endl;

//	vector<string> explanatoryVariables;
//
//	//DATA FROM LIU
//	string v1R1 = "./MyProjects/HFM/Instance/Physionet/S001R01/Channel-1";
////	string v1R2 = "./MyProjects/HFM/Instance/Physionet/S001R02/Channel-11";
////	string v2R1 = "./MyProjects/HFM/Instance/Physionet/S002R01/Channel-11";
////	string v2R2 = "./MyProjects/HFM/Instance/Physionet/S002R02/Channel-11";
//	//	vTimeSeriesVoluntersChannels.push_back(v2R1);
//	//	vTimeSeriesVoluntersChannels.push_back(v2R2);

	vector<vector<pair<Solution<RepEFP>&, Evaluation&>*> > setOfVolunteersLearningModels;
	vector<vector<vector<double> > > setOfVolunteersStandardErrors;
	//learning one model -- from channel 1 -- for each volunter

	vector<int> listOfIndicatorOfQuality;
	// this next, listOfIndicatorOfQualityWeights, vector is used in the decision making
	// it indicates the importance of each indicator of quality in order to analyze which is the most suitable model for that time series
	vector<int> listOfIndicatorOfQualityWeights;

	listOfIndicatorOfQuality.push_back(MAPE_INDEX);
	listOfIndicatorOfQualityWeights.push_back(1);

	listOfIndicatorOfQuality.push_back(MSE_INDEX);
	listOfIndicatorOfQualityWeights.push_back(1);

	listOfIndicatorOfQuality.push_back(RMSE_INDEX);
	listOfIndicatorOfQualityWeights.push_back(1);

	listOfIndicatorOfQuality.push_back(SMAPE_INDEX);
	listOfIndicatorOfQualityWeights.push_back(3);

	listOfIndicatorOfQuality.push_back(WMAPE_INDEX);
	listOfIndicatorOfQualityWeights.push_back(1);

	int nIndicatorsOfQuality = listOfIndicatorOfQuality.size();

	for (int v = 0; v < nVolunters; v++)
	{
		vector<pair<Solution<RepEFP>&, Evaluation&>*> setOfLearningModels;
		vector<vector<double> > setOfModelsStandardErrors;
		for (int nM = 0; nM < maxNM; nM++)
		{
			int randomChannel = rg.rand(64) + 1;
			cout << "training model " << nM << " of Volunteer " << v << endl;
			stringstream EEGTimeSeriesToBeLearned;
//			EEGTimeSeriesToBeLearned << "./MyProjects/HFM/Instance/Physionet/S00" << v + 1 << "R01/Channel-1";
			EEGTimeSeriesToBeLearned << "./MyProjects/HFM/Instance/Physionet/S00" << v + 1 << "R01/Channel-" << randomChannel;

			vector<string> explanatoryVariables;
			explanatoryVariables.push_back(EEGTimeSeriesToBeLearned.str());

			int trainingTime = rg.rand(argvTimeES) + 30;
			int evalIQ = listOfIndicatorOfQuality[rg.rand(nIndicatorsOfQuality)];

			pair<Solution<RepEFP>&, Evaluation&>* HFMmodel = learnModel(explanatoryVariables, argvMaxLagRate, trainingTime, seed, rg, evalIQ);
			setOfLearningModels.push_back(HFMmodel);

			vector<double> allErrors = checkLearningAbility(explanatoryVariables, HFMmodel, argvMaxLagRate, rg);
			setOfModelsStandardErrors.push_back(allErrors);
		}

		setOfVolunteersLearningModels.push_back(setOfLearningModels);
		setOfVolunteersStandardErrors.push_back(setOfModelsStandardErrors);
	}

	cout << "The different time series has been learned with success!" << endl;
	//Checking the performance of each HFM model in different EEG channels of different inviduals
	// A different experiment is verified

	int nChannels = 64;
	for (int hiddenV = 0; hiddenV < nVolunters; hiddenV++) // how is volunter v?
	{
		Matrix<double> results(nIndicatorsOfQuality, nVolunters);
		Matrix<double> resultsMin(nIndicatorsOfQuality, nVolunters);
		Matrix<double> resultsMax(nIndicatorsOfQuality, nVolunters);
		Matrix<double> resultsGAP(nIndicatorsOfQuality, nVolunters);
		cout << "============================================\n" << endl;

		for (int v = 0; v < nVolunters; v++)
		{
			vector<double> sumOfErrors(nIndicatorsOfQuality, 0);
			vector<double> minErrors(nIndicatorsOfQuality, 100000000);
			vector<double> maxErrors(nIndicatorsOfQuality, -10000000);
			vector<double> sumOfGAP(nIndicatorsOfQuality, 0);

			for (int nM = 0; nM < maxNM; nM++)
			{
				pair<Solution<RepEFP>&, Evaluation&>* HFMmodel = setOfVolunteersLearningModels[v][nM];
				vector<double> modelStandardErrors = setOfVolunteersStandardErrors[v][nM];

				for (int i = 0; i < nChannels; i++)
				{
					stringstream checkError;
					checkError << "./MyProjects/HFM/Instance/Physionet/S00" << hiddenV + 1 << "R02/Channel-" << i + 1;
					vector<string> validationExplanotoryVariables;
					validationExplanotoryVariables.push_back(checkError.str());
//				cout << "checking performance on " << checkError.str() << endl;

					vector<double> currentErrors;
					vector<double> allErrors = checkLearningAbility(validationExplanotoryVariables, HFMmodel, argvMaxLagRate, rg);
					for (int iq = 0; iq < listOfIndicatorOfQuality.size(); iq++)
						currentErrors.push_back(allErrors[listOfIndicatorOfQuality[iq]]);

					for (int m = 0; m < nIndicatorsOfQuality; m++)
					{
						sumOfErrors[m] += currentErrors[m];
						if (currentErrors[m] < minErrors[m])
							minErrors[m] = currentErrors[m];

						if (currentErrors[m] > maxErrors[m])
							maxErrors[m] = currentErrors[m];

						sumOfGAP[m] += abs(modelStandardErrors[m] - currentErrors[m]);
					}

				}

			}

			for (int m = 0; m < nIndicatorsOfQuality; m++)
			{
				sumOfErrors[m] /= (nChannels * maxNM);
				sumOfGAP[m] /= (nChannels * maxNM);

				results(m, v) = sumOfErrors[m];
				resultsMin(m, v) = minErrors[m];
				resultsMax(m, v) = maxErrors[m];
				resultsGAP(m, v) = sumOfGAP[m];
			}

			cout << "Average errors of " << maxNM << " models from volunteer:" << v << "-->" << hiddenV << " | applied to discover channels values from exp 2" << endl;
			//<< " applied over all  errors vollunter " << v2 + 1 << " -- All channels from exp 2" << endl;
			cout << sumOfErrors << endl;

			cout << "Min errors of " << maxNM << " models from volunteer:" << v << "-->" << hiddenV << " | applied to discover channels values from exp 2" << endl;
			//<< " applied over all  errors vollunter " << v2 + 1 << " -- All channels from exp 2" << endl;
			cout << minErrors << endl;

			cout << "Max errors of " << maxNM << " models from volunteer:" << v << "-->" << hiddenV << " | applied to discover channels values from exp 2" << endl;
			cout << maxErrors << endl;

			cout << "GAPS against standard errors of " << maxNM << " models from volunteer:" << v << "-->" << hiddenV << " | applied to discover channels values from exp 2" << endl;
			cout << sumOfGAP << endl << endl;

		}

		cout << "AVG\n";
		vector<pair<double, int> > lowerPairAVG = printLowerMatrixValues(results, true);
		cout << lowerPairAVG << endl;

		cout << "MIN\n";
		vector<pair<double, int> > lowerPairMIN = printLowerMatrixValues(resultsMin, true);
		cout << lowerPairMIN << endl;

		cout << "MAX\n";
		vector<pair<double, int> > lowerPairMAX = printLowerMatrixValues(resultsMax, false);
		cout << lowerPairMAX << endl;

		cout << "GAP\n";
		vector<pair<double, int> > lowerPairGAP = printLowerMatrixValues(resultsGAP, true);
		cout << lowerPairGAP << endl;

		vector<pair<int, int> > volunteerPoints = decisionMaking(lowerPairAVG, lowerPairMIN, lowerPairMAX, lowerPairGAP, listOfIndicatorOfQualityWeights, nVolunters);
		cout << "\n Model from volunteer:" << volunteerPoints[0].first << " has the highest score to fit the unknown time series:" << hiddenV << endl;
		cout << volunteerPoints << endl;

		vector<pair<int, int> > volunteerPoints2 = decisionMaking2(results, resultsMin, resultsMax, resultsGAP, listOfIndicatorOfQualityWeights);
		cout << "\n Metric 2 -- Model from volunteer:" << volunteerPoints2[0].first << " has the highest score to fit the unknown time series:" << hiddenV << endl;
		cout << volunteerPoints2 << endl;

		cout << "===================================================\n" << endl;

	}

	return 0;
}

