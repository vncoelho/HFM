// ===================================
// Main.cpp file generated by OptFrame
// Project EFP
// ===================================

#include <stdlib.h>
#include <math.h>
#include <iostream>
#include <numeric>
#include <iomanip>
#include "../../../OptFrame/RandGen.hpp"
#include "../../../OptFrame/Util/RandGenMersenneTwister.hpp"

using namespace std;
using namespace optframe;
using namespace EFP;

struct HFMModelAndParam
{
	pair<Solution<RepEFP>&, Evaluation&>* HFMModel;
	vector<double> forecastingErrors;
	int fH;
	int v; //volunteer which was used to train the data
	int channel; //volunteer channel which was used to train the data

	HFMModelAndParam(pair<Solution<RepEFP>&, Evaluation&>* _HFMModel, vector<double> _forecastingErrors, int _fH, int _v, int _channel) :
			HFMModel(_HFMModel), forecastingErrors(_forecastingErrors), fH(_fH), v(_v), channel(_channel)
	{
	}
};

static bool comparaVolunteersPoints(pair<int, int> d1, pair<int, int> d2)
{
	return d1.second > d2.second;
}

static bool comparaVolunteersPoints2(pair<int, int> d1, pair<int, int> d2)
{
	return d1.second < d2.second;
}

vector<pair<int, int> > decisionMaking(vector<pair<double, int> > betterAVG, vector<pair<double, int> > betterMin, vector<pair<double, int> > betterMax, vector<pair<double, int> > betterGAP, vector<int> metricWeights, int nVolunteers)
{
	int nIQ = metricWeights.size(); //number of indicators of quality
	int avgWeight = 4;
	int minWeight = 1;
	int maxWeight = 1;
	int gapWeight = 3;
	vector<pair<int, int> > volunteersPoints(nVolunteers);
	for (int v = 0; v < nVolunteers; v++)
		volunteersPoints[v] = make_pair(v, 0);

	for (int m = 0; m < nIQ; m++)
	{
		volunteersPoints[betterAVG[m].second].second += metricWeights[m] * avgWeight;
		volunteersPoints[betterMin[m].second].second += metricWeights[m] * minWeight;
		volunteersPoints[betterMax[m].second].second -= metricWeights[m] * maxWeight;
		volunteersPoints[betterGAP[m].second].second += metricWeights[m] * gapWeight;
	}

	sort(volunteersPoints.begin(), volunteersPoints.end(), comparaVolunteersPoints); // ordena com QuickSort

//	cout << volunteersPoints << endl;
	return volunteersPoints;
}

vector<pair<int, int> > decisionMaking3(vector<pair<double, int> > betterAVG, vector<pair<double, int> > betterMin, vector<pair<double, int> > betterMax, vector<pair<double, int> > betterGAP, vector<int> metricWeights, int nVolunteers)
{
	int nIQ = metricWeights.size(); //number of indicators of quality
	int avgWeight = 4;
	int minWeight = 1;
	int maxWeight = 1;
	int gapWeight = 3;
	vector<pair<int, int> > volunteersPoints(nVolunteers);
	for (int v = 0; v < nVolunteers; v++)
		volunteersPoints[v] = make_pair(v, 0);

	for (int m = 0; m < nIQ; m++)
	{
		volunteersPoints[betterAVG[m].second].second += metricWeights[m] * avgWeight;
		volunteersPoints[betterMin[m].second].second += metricWeights[m] * minWeight;
		volunteersPoints[betterMax[m].second].second += metricWeights[m] * maxWeight;
		volunteersPoints[betterGAP[m].second].second += metricWeights[m] * gapWeight;
	}

	sort(volunteersPoints.begin(), volunteersPoints.end(), comparaVolunteersPoints); // ordena com QuickSort

//	cout << volunteersPoints << endl;
	return volunteersPoints;
}

vector<pair<int, int> > decisionMaking2(Matrix<double> resultsAVG, Matrix<double> resultsMIN, Matrix<double> resultsMAX, Matrix<double> resultsGAP, vector<int> metricWeights)
{
	int nVolunteers = resultsAVG.getNumCols();
	int nIQ = metricWeights.size(); //number of indicators of quality
	int avgWeight = 4;
	int minWeight = 1;
	int maxWeight = 1;
	int gapWeight = 3;

	vector<pair<int, int> > volunteersPoints(nVolunteers);
	for (int v = 0; v < nVolunteers; v++)
		volunteersPoints[v] = make_pair(v, 0);

	for (int m = 0; m < nIQ; m++)
	{
		vector<pair<int, double> > avgOrder(nVolunteers);

		vector<pair<int, double> > minOrder(nVolunteers);

		vector<pair<int, double> > maxOrder(nVolunteers);
		vector<pair<int, double> > gapOrder(nVolunteers);
		for (int v = 0; v < nVolunteers; v++)
		{
			avgOrder[v] = make_pair(v, resultsAVG(m, v));
			minOrder[v] = make_pair(v, resultsMIN(m, v));
			maxOrder[v] = make_pair(v, resultsMAX(m, v));
			gapOrder[v] = make_pair(v, resultsGAP(m, v));
		}
		sort(avgOrder.begin(), avgOrder.end(), comparaVolunteersPoints); // ordena com QuickSort
		sort(minOrder.begin(), minOrder.end(), comparaVolunteersPoints); // ordena com QuickSort
		sort(maxOrder.begin(), maxOrder.end(), comparaVolunteersPoints2); // ordena com QuickSort
		sort(gapOrder.begin(), gapOrder.end(), comparaVolunteersPoints); // ordena com QuickSort

//		cout << "ordered values for different IQ:" << m << endl;
//		cout << avgOrder << endl;
//		cout << minOrder << endl;
//		cout << maxOrder << endl;
//		cout << gapOrder << endl << endl;
//		getchar();
		for (int v = 0; v < nVolunteers; v++)
		{
			volunteersPoints[avgOrder[v].first].second += (metricWeights[m] * avgWeight * (v + 1));
			volunteersPoints[minOrder[v].first].second += (metricWeights[m] * minWeight * (v + 1));
			volunteersPoints[maxOrder[v].first].second -= (metricWeights[m] * maxWeight * (v + 1));
			volunteersPoints[gapOrder[v].first].second += (metricWeights[m] * gapWeight * (v + 1));
//			volunteersPoints[avgOrder[v].first].second += (1 * avgWeight * (v + 1));
//			volunteersPoints[minOrder[v].first].second += (1 * minWeight * (v + 1));
//			volunteersPoints[maxOrder[v].first].second -= (1 * maxWeight * (v + 1));
//			volunteersPoints[gapOrder[v].first].second += (1 * gapWeight * (v + 1));
		}

	}

	sort(volunteersPoints.begin(), volunteersPoints.end(), comparaVolunteersPoints); // ordena com QuickSort

//	cout << volunteersPoints << endl;

	return volunteersPoints;
}

vector<pair<double, int> > findBestPairsValuesByMetric(Matrix<double> results, bool minOrMax)
{
	int nIQ = results.getNumRows(); //number of indicators of quality
	vector<pair<double, int> > bestPairs(nIQ);

	double bigM = 10000000000;
	for (int m = 0; m < nIQ; m++)
	{
		double minMaxError;
		if (minOrMax == true)
		{
			minMaxError = bigM;
		}
		else
		{
			minMaxError = -bigM;
		}

		int minColIndex = -1;

		for (int v = 0; v < results.getNumCols(); v++)
		{
			if (minOrMax == true)
			{
				if (results(m, v) < minMaxError)
				{
					minMaxError = results(m, v);
					minColIndex = v;
				}
			}
			else
			{
				if (results(m, v) > minMaxError)
				{
					minMaxError = results(m, v);
					minColIndex = v;
				}
			}

		}

		bestPairs[m] = make_pair(minMaxError, minColIndex);

	}

	return bestPairs;
}

pair<Solution<RepEFP>&, Evaluation&>* learnModel(treatForecasts& tFTraining, int argvMaxLagRate, int argvTimeES, long seed, RandGen& rg, int evalFO, int _contructiveNumberOfRules, int _sa)
{

	int mu = 100;
	int lambda = mu * 6;
	int evalFOMinimizer = evalFO;
	int contructiveNumberOfRules = _contructiveNumberOfRules;
	int evalAprox = 0;
	double alphaACF = -1;
	int construtive = 2;
	int nSA = _sa;

	// ============ END FORCES ======================

	// ============= METHOD PARAMETERS=================
	methodParameters methodParam;
	//seting up Continous ES params
	methodParam.setESInitialDesv(10);
	methodParam.setESMutationDesv(20);
	methodParam.setESMaxG(100000);

	//seting up ES params
	methodParam.setESMU(mu);
	methodParam.setESLambda(lambda);

	//seting up ACF construtive params
	methodParam.setConstrutiveMethod(construtive);
	methodParam.setConstrutivePrecision(contructiveNumberOfRules);
	vector<double> vAlphaACFlimits;
	vAlphaACFlimits.push_back(alphaACF);
	methodParam.setConstrutiveLimitAlphaACF(vAlphaACFlimits);

	//seting up Eval params
	methodParam.setEvalAprox(evalAprox);
	methodParam.setEvalFOMinimizer(evalFOMinimizer);
	// ==========================================

	// ================== READ FILE ============== CONSTRUTIVE 0 AND 1
	ProblemParameters problemParam;
	//ProblemParameters problemParam(vParametersFiles[randomParametersFiles]);

	problemParam.setStepsAhead(nSA);
	int stepsAhead = problemParam.getStepsAhead();

	int nTotalForecastingsTrainningSet = tFTraining.getForecastsSize(0);

	cout << "ContructiveACF HFM maximum number of Rules: " << contructiveNumberOfRules << endl;
	//========SET PROBLEM MAXIMUM LAG ===============
	cout << "argvMaxLagRate: " << argvMaxLagRate << endl;

	int iterationMaxLag = ((nTotalForecastingsTrainningSet - stepsAhead) * argvMaxLagRate) / 100.0;
	iterationMaxLag = ceil(iterationMaxLag);
	if (iterationMaxLag > (nTotalForecastingsTrainningSet - stepsAhead))
		iterationMaxLag--;
	if (iterationMaxLag <= 0)
		iterationMaxLag = 1;

	problemParam.setMaxLag(iterationMaxLag);
	int maxLag = problemParam.getMaxLag();

	//If maxUpperLag is greater than 0 model uses predicted data
	problemParam.setMaxUpperLag(0);
	//int maxUpperLag = problemParam.getMaxUpperLag();
	//=================================================

	int timeES = argvTimeES; // online training time

	vector<double> foIndicators;

	int beginTrainingSet = 0;
	//int nTrainningRounds = 3;
	//int nTotalForecastingsTrainningSet = maxLag + nTrainningRounds * stepsAhead;

	cout << std::setprecision(9);
	cout << std::fixed;
	double NTRaprox = (nTotalForecastingsTrainningSet - maxLag) / double(stepsAhead);
	cout << "BeginTrainninningSet: " << beginTrainingSet << endl;
	cout << "#nTotalForecastingsTrainningSet: " << nTotalForecastingsTrainningSet << endl;
	cout << "#~NTR: " << NTRaprox << endl;
	cout << "#sizeTrainingSet: " << tFTraining.getForecastsSize(0) << endl;
	cout << "#maxNotUsed: " << maxLag << endl;
	cout << "#StepsAhead: " << stepsAhead << endl << endl;

	vector<vector<double> > trainningSet = tFTraining.getTS();
	; // trainningSetVector
	  //trainningSet.push_back(rF.getPartsForecastsEndToBegin(0, 0, nTotalForecastingsTrainningSet));

//	trainningSet.push_back(tFTraining.getPartsForecastsEndToBegin(0, 0, nTotalForecastingsTrainningSet));

	ForecastClass forecastObject(trainningSet, problemParam, rg, methodParam);

	//		forecastObject.runMultiObjSearch();
	//		getchar();
	pair<Solution<RepEFP>&, Evaluation&>* sol;
	sol = forecastObject.run(timeES, 0, 0);
//	sol = forecastObject.runEFP(5,timeES);

//	vector<double> foIndicatorCalibration;
//	vector<vector<double> > validationSet;
//	validationSet.push_back(rF.getPartsForecastsEndToBegin(0, 0, maxLag + stepsAhead));
//	vector<double> errors = forecastObject.returnErrors(sol, validationSet);
//
//	foIndicators.push_back(errors[SMAPE_INDEX]);
//	foIndicators.push_back(sol->second.evaluation());
//	foIndicators.push_back(argvMaxLagRate);
//	foIndicators.push_back(maxLag);
//	foIndicators.push_back(NTRaprox);
//	foIndicators.push_back(timeES);
//	foIndicators.push_back(seed);
//	vfoIndicatorCalibration.push_back(foIndicators);

	return sol;

}

vector<double> checkLearningAbility(treatForecasts& tFValidation, pair<Solution<RepEFP>&, Evaluation&>* sol, RandGen& rg, int _sa)
{

	int mu = 100;
	int lambda = mu * 6;
	int evalFOMinimizer = SMAPE_INDEX;
	int contructiveNumberOfRules = 100;
	int evalAprox = 0;
	double alphaACF = -1;
	int construtive = 2;
	int nSA = _sa;
	// ============ END FORCES ======================

	// ============= METHOD PARAMETERS=================
	methodParameters methodParam;
	//seting up Continous ES params
	methodParam.setESInitialDesv(10);
	methodParam.setESMutationDesv(20);
	methodParam.setESMaxG(100000);

	//seting up ES params
	methodParam.setESMU(mu);
	methodParam.setESLambda(lambda);

	//seting up ACF construtive params
	methodParam.setConstrutiveMethod(construtive);
	methodParam.setConstrutivePrecision(contructiveNumberOfRules);
	vector<double> vAlphaACFlimits;
	vAlphaACFlimits.push_back(alphaACF);
	methodParam.setConstrutiveLimitAlphaACF(vAlphaACFlimits);

	//seting up Eval params
	methodParam.setEvalAprox(evalAprox);
	methodParam.setEvalFOMinimizer(evalFOMinimizer);
	// ==========================================

	// ================== READ FILE ============== CONSTRUTIVE 0 AND 1
	ProblemParameters problemParam;
	//ProblemParameters problemParam(vParametersFiles[randomParametersFiles]);

	problemParam.setStepsAhead(nSA);
	int stepsAhead = problemParam.getStepsAhead();

	int nTotalForecastingsTrainningSet = tFValidation.getForecastsSize(0);

	//========SET PROBLEM MAXIMUM LAG ===============
	problemParam.setMaxLag(sol->first.getR().earliestInput);
	int maxLag = problemParam.getMaxLag();

	if (nTotalForecastingsTrainningSet < (maxLag + stepsAhead))
	{
		cout << "ERROR on learnModel -- small TS size " << endl;
		cout << "nTotalForecastingsTrainningSet:" << nTotalForecastingsTrainningSet << "\tmaxLag + stepsAhead:" << maxLag + stepsAhead << endl;
	}

	//If maxUpperLag is greater than 0 model uses predicted data
	problemParam.setMaxUpperLag(0);
	//int maxUpperLag = problemParam.getMaxUpperLag();
	//=================================================
	vector<double> foIndicators;
	//this is a problem due to the difference between the size using argvMaxLagRate

	vector<vector<double> > validationSet = tFValidation.getTS();
//	validationSet.push_back(tFValidation.getPartsForecastsEndToBegin(0, 0, nTotalForecastingsTrainningSet));
//cout<<validationSet<<endl;
//getchar();

	ForecastClass forecastObject(validationSet, problemParam, rg, methodParam);

	vector<double> errors = forecastObject.returnErrors(sol, validationSet);
	return errors;
}

int EEGLearning(int argc, char **argv)
{
	cout << "Welcome to EEG learning module!" << endl;
	RandGenMersenneTwister rg;
	//long  1412730737
	long seed = time(NULL); //CalibrationMode
	seed = 1;
	cout << "Seed = " << seed << endl;
	srand(seed);
	rg.setSeed(seed);

	int argvMaxLagRate = 3; // percentage of ts to be used
	int argvTimeES = 5;
	int minTime = 0; // not used for now, since the random training time seams to be a bad idea TODO
	int nVolunters = 4;
	int maxNM = 1;
	int argvFH = 20;

	//=============================================
	//Learning instance and validation

	double trainingSetPercentage = 0.7;
	double validationSetPercentage = 1 - trainingSetPercentage;
	trainingSetPercentage = 1;
	validationSetPercentage = 1;

	//Training experiment - 1 to 14
	int expT = 2;
	int expV = 1;

	//Channel to be trained and channel to be validated
	int fixedChannelT = 30;
	int fixedChannelV = 30;

	cout << "expT: " << expT << " -- channel: " << fixedChannelT << " with " << trainingSetPercentage * 100 << "%" << endl;
	cout << "expV: " << expV << " -- channel: " << fixedChannelV << " with " << validationSetPercentage * 100 << "%" << endl;
	//=============================================

	//===================================
	cout << "===========================" << endl;
	cout << "Input parameters:" << endl;
	cout << "nVolunters:" << nVolunters << endl;
	cout << "number of models per volunteer:" << maxNM << endl;
	cout << "argvMaxLagRate:" << argvMaxLagRate << endl;
	cout << "argvTimeES:" << argvTimeES << endl;
	cout << "argvFH:" << argvFH << endl;
	cout << "===========================" << endl << endl;

//	vector<string> explanatoryVariables;
//
//	//DATA FROM LIU
//	string v1R1 = "./MyProjects/HFM/Instance/Physionet/S001R01/Channel-1";
////	string v1R2 = "./MyProjects/HFM/Instance/Physionet/S001R02/Channel-11";
////	string v2R1 = "./MyProjects/HFM/Instance/Physionet/S002R01/Channel-11";
////	string v2R2 = "./MyProjects/HFM/Instance/Physionet/S002R02/Channel-11";
//	//	vTimeSeriesVoluntersChannels.push_back(v2R1);
//	//	vTimeSeriesVoluntersChannels.push_back(v2R2);

	//vector that carries each model that were trained and its characteristics and parameters
	vector<vector<HFMModelAndParam*> > setOfVolunteersHFMLearningModels;
//	vector<vector<pair<Solution<RepEFP>&, Evaluation&>*> > setOfVolunteersLearningModels;
//	vector<vector<vector<double> > > setOfVolunteersStandardErrors;

	vector<int> listOfIndicatorOfQuality;
	// this next, listOfIndicatorOfQualityWeights, vector is used in the decision making
	// it indicates the importance of each indicator of quality in order to analyze which is the most suitable model for that time series
	vector<int> listOfIndicatorOfQualityWeights;

	listOfIndicatorOfQuality.push_back(MAPE_INDEX);
	listOfIndicatorOfQualityWeights.push_back(1);

	listOfIndicatorOfQuality.push_back(MSE_INDEX);
	listOfIndicatorOfQualityWeights.push_back(1);

	listOfIndicatorOfQuality.push_back(RMSE_INDEX);
	listOfIndicatorOfQualityWeights.push_back(1);

	listOfIndicatorOfQuality.push_back(SMAPE_INDEX);
	listOfIndicatorOfQualityWeights.push_back(1);

	listOfIndicatorOfQuality.push_back(WMAPE_INDEX);
	listOfIndicatorOfQualityWeights.push_back(1);

	//TODO
	//new indicators of quality, intrisic looking at the predictes values and comparing them to the real EEG should be developed

	int nIndicatorsOfQuality = listOfIndicatorOfQuality.size();

	vector<int> channelsToBeLearned;
	for (int c = 1; c <= 64; c++)
	{
		channelsToBeLearned.push_back(c);
	}

	for (int v = 0; v < nVolunters; v++)
	{
//		vector<pair<Solution<RepEFP>&, Evaluation&>*> setOfLearningModels;
//		vector<vector<double> > setOfModelsStandardErrors;
		vector<HFMModelAndParam*> setOfHFMLearningModels;
		for (int nM = 0; nM < maxNM; nM++)
		{
//			int randomChannel = rg.rand(64) + 1;
//			randomChannel = 40;
			int variableChannelT = channelsToBeLearned[nM];
			cout << "\nTraining model " << nM + 1 << "/" << maxNM << " of Volunteer " << v << " -- EEG Channel " << variableChannelT << " -- exp" << expT << endl;

			stringstream EEGTimeSeriesToBeLearned;
			stringstream sName;
//			EEGTimeSeriesToBeLearned << "./MyProjects/HFM/Instance/Physionet/S00" << v + 1 << "R01/Channel-1";
			if (v + 1 <= 9)
				sName << "S00";
			else if (v + 1 <= 99)
				sName << "S0";
			else
				sName << "S";
			//EEGTimeSeriesToBeLearned << "./MyProjects/HFM/Instance/Physionet/" << sName.str() << v + 1 << "R0" << expT << "/Channel-" << fixedChannelT;
			EEGTimeSeriesToBeLearned << "./MyProjects/HFM/Instance/Physionet/" << sName.str() << v + 1 << "R0" << expT << "/Channel-" << variableChannelT;

			vector<string> explanatoryVariables;
			explanatoryVariables.push_back(EEGTimeSeriesToBeLearned.str());

//			int trainingTime = rg.rand(argvTimeES) + minTime;
			int trainingTime = argvTimeES;
			int evalFO = listOfIndicatorOfQuality[rg.rand(nIndicatorsOfQuality)];
			int contructiveNumberOfRules = 100;
			int fH = argvFH;	// rg.rand(argvFH) + 1; //forecasting horizon
			cout << "forcing some values in the learning phase!" << endl;
			evalFO = SMAPE_INDEX;

			treatForecasts tFTraining(explanatoryVariables);
			tFTraining.setTSFile(tFTraining.getPercentageFromBeginToEnd(0, 0, trainingSetPercentage), 0);

			pair<Solution<RepEFP>&, Evaluation&>* HFMmodel = learnModel(tFTraining, argvMaxLagRate, trainingTime, seed, rg, evalFO, contructiveNumberOfRules, fH);
//			setOfLearningModels.push_back(HFMmodel);
//			cout << "sol->first.getR().earliestInput: " << HFMmodel->first.getR().earliestInput << endl;
//			cout<<HFMmodel->first.getR()<<endl;
//			getchar();

			vector<double> allErrors = checkLearningAbility(tFTraining, HFMmodel, rg, fH);
//			cout << allErrors << endl;
//			getchar();
			vector<double> currentErrors;
			for (int iq = 0; iq < listOfIndicatorOfQuality.size(); iq++)
				currentErrors.push_back(allErrors[listOfIndicatorOfQuality[iq]]);

//			setOfModelsStandardErrors.push_back(currentErrors);
			HFMModelAndParam* HFMCurrentModelAndParams = new HFMModelAndParam(HFMmodel, currentErrors, fH, v, variableChannelT);
			setOfHFMLearningModels.push_back(HFMCurrentModelAndParams);

		}
		setOfVolunteersHFMLearningModels.push_back(setOfHFMLearningModels);
//		setOfVolunteersLearningModels.push_back(setOfLearningModels);
//		setOfVolunteersStandardErrors.push_back(setOfModelsStandardErrors);
	}

	cout << "The different time series has been learned with success!\n" << endl;
	cout << "Time to check their performance...\n" << endl;

	//Checking the performance of each HFM model in different EEG channels of different inviduals
	// A different experiment is verified
	int nTruePositivesM1 = 0;
	int nTruePositivesM2 = 0;
	int nTruePositivesM3 = 0;
//	int nChannels = 1;
	for (int hiddenV = 0; hiddenV < nVolunters; hiddenV++) // how is volunter v?
	{
		Matrix<double> results(nIndicatorsOfQuality, nVolunters);
		Matrix<double> resultsMin(nIndicatorsOfQuality, nVolunters);
		Matrix<double> resultsMax(nIndicatorsOfQuality, nVolunters);
		Matrix<double> resultsGAP(nIndicatorsOfQuality, nVolunters);
		cout << "===================================================\n" << endl;

		vector<vector<vector<double> > > allValidations;

		for (int v = 0; v < nVolunters; v++)
		{
			vector<double> sumOfErrors(nIndicatorsOfQuality, 0);
			vector<double> minErrors(nIndicatorsOfQuality, 1000000000);
			vector<double> maxErrors(nIndicatorsOfQuality, -100000000);
			vector<double> sumOfGAP(nIndicatorsOfQuality, 0);

			vector<vector<double> > allValidationsByVolunter;

			for (int nM = 0; nM < maxNM; nM++)
			{
				pair<Solution<RepEFP>&, Evaluation&>* HFMmodel = setOfVolunteersHFMLearningModels[v][nM]->HFMModel;
				vector<double> modelStandardErrors = setOfVolunteersHFMLearningModels[v][nM]->forecastingErrors;
				int modelFH = setOfVolunteersHFMLearningModels[v][nM]->fH;
				int variableChannelV = setOfVolunteersHFMLearningModels[v][nM]->channel;


				stringstream checkError;
				stringstream sName;
				if (hiddenV + 1 <= 9)
					sName << "S00";
				else if (hiddenV + 1 <= 99)
					sName << "S0";
				else
					sName << "S";
				//checkError << "./MyProjects/HFM/Instance/Physionet/S00" << hiddenV + 1 << "R01/Channel-" << i + 1;
				//checkError << "./MyProjects/HFM/Instance/Physionet/" << sName.str() << hiddenV + 1 << "R0" << expV << "/Channel-" << fixedChannelV;
				checkError << "./MyProjects/HFM/Instance/Physionet/" << sName.str() << hiddenV + 1 << "R0" << expV << "/Channel-" << variableChannelV;
				vector<string> validationExplanotoryVariables;
				validationExplanotoryVariables.push_back(checkError.str());
//				cout << "checking performance on " << checkError.str() << endl;

				vector<double> currentErrors;

				treatForecasts tFValidation(validationExplanotoryVariables);
				tFValidation.setTSFile(tFValidation.getPercentageFromEndToBegin(0, 0, validationSetPercentage), 0);

				vector<double> allErrors = checkLearningAbility(tFValidation, HFMmodel, rg, modelFH);

				for (int iq = 0; iq < listOfIndicatorOfQuality.size(); iq++)
					currentErrors.push_back(allErrors[listOfIndicatorOfQuality[iq]]);

				allValidationsByVolunter.push_back(currentErrors);

				for (int m = 0; m < nIndicatorsOfQuality; m++)
				{
					sumOfErrors[m] += currentErrors[m];

					if (currentErrors[m] < minErrors[m])
						minErrors[m] = currentErrors[m];

					if (currentErrors[m] > maxErrors[m])
						maxErrors[m] = currentErrors[m];

					sumOfGAP[m] += abs(modelStandardErrors[m] - currentErrors[m]);
				}

			}

			allValidations.push_back(allValidationsByVolunter);

			for (int m = 0; m < nIndicatorsOfQuality; m++)
			{
				sumOfErrors[m] /= maxNM;
				sumOfGAP[m] /= maxNM;

				results(m, v) = sumOfErrors[m];
				resultsMin(m, v) = minErrors[m];
				resultsMax(m, v) = maxErrors[m];
				resultsGAP(m, v) = sumOfGAP[m];
			}

			cout << maxNM << " models from volunteer:" << v << "-->" << hiddenV << endl;

			cout << "Average errors" << endl;
			//<< " applied over all  errors vollunter " << v2 + 1 << " -- All channels from exp 2" << endl;
			cout << sumOfErrors << endl;

			cout << "Min errors" << endl;
			//<< " applied over all  errors vollunter " << v2 + 1 << " -- All channels from exp 2" << endl;
			cout << minErrors << endl;

			cout << "Max errors" << endl;
			cout << maxErrors << endl;

			cout << "GAPS against standard errors" << endl;
			cout << sumOfGAP << endl << endl;
//			getchar();

		}

		vector<pair<double, int> > lowerPairAVG = findBestPairsValuesByMetric(results, true);
		vector<pair<double, int> > lowerPairMIN = findBestPairsValuesByMetric(resultsMin, true);
		vector<pair<double, int> > highestPairMAX = findBestPairsValuesByMetric(resultsMax, false);
		vector<pair<double, int> > lowestPairMAX = findBestPairsValuesByMetric(resultsMax, true);
		vector<pair<double, int> > lowerPairGAP = findBestPairsValuesByMetric(resultsGAP, true);

//		cout << "AVG\n";
//		cout << lowerPairAVG << endl;
//		cout << results << endl;
//
//		cout << "MIN\n";
//		cout << lowerPairMIN << endl;
//		cout << resultsMin << endl;
//
//		cout << "MAX\n";
//		cout << highestPairMAX << endl;
//		cout << lowestPairMAX << endl;
//		cout << resultsMax << endl;
//
//		cout << "GAP\n";
//		cout << lowerPairGAP << endl;
//		cout << resultsGAP << endl;
//		getchar();

		vector<pair<int, int> > volunteerPoints = decisionMaking(lowerPairAVG, lowerPairMIN, highestPairMAX, lowerPairGAP, listOfIndicatorOfQualityWeights, nVolunters);
		cout << "\nM1 -- Model from volunteer: " << volunteerPoints[0].first << " is the most suitable for ts: " << hiddenV << endl;
		cout << volunteerPoints << endl;

		vector<pair<int, int> > volunteerPoints2 = decisionMaking2(results, resultsMin, resultsMax, resultsGAP, listOfIndicatorOfQualityWeights);
		cout << "\nM2 -- Model from volunteer: " << volunteerPoints2[0].first << " is the most suitable for ts: " << hiddenV << endl;
		cout << volunteerPoints2 << endl;

		vector<pair<int, int> > volunteerPoints3 = decisionMaking3(lowerPairAVG, lowerPairMIN, lowestPairMAX, lowerPairGAP, listOfIndicatorOfQualityWeights, nVolunters);
		cout << "\nM3 -- Model from volunteer: " << volunteerPoints3[0].first << " is the most suitable for ts: " << hiddenV << endl;
		cout << volunteerPoints << endl;

		//Checking true positives
		if (volunteerPoints[0].first == hiddenV)
			nTruePositivesM1++;

		if (volunteerPoints2[0].first == hiddenV)
			nTruePositivesM2++;

		if (volunteerPoints3[0].first == hiddenV)
			nTruePositivesM3++;

		cout << "===================================================\n" << endl;

	}
	cout << "===================================================\n" << endl;
	cout << "True positives are:\n" << "M1:" << nTruePositivesM1 << "\tM2:" << nTruePositivesM2 << "\tM3:" << nTruePositivesM3 << endl;
	double volunteerPointsM1Percentage = double(100.0 * nTruePositivesM1 / nVolunters);
	double volunteerPointsM2Percentage = 100.0 * nTruePositivesM2 / nVolunters;
	double volunteerPointsM3Percentage = 100.0 * nTruePositivesM3 / nVolunters;
	cout << "True percentage are:\n" << "M1:" << volunteerPointsM1Percentage << "\tM2:" << volunteerPointsM2Percentage << "\tM3:" << volunteerPointsM3Percentage << endl;
	cout << "===================================================\n" << endl;

	// =================== PRINTING RESULTS ON FILE ========================
	string calibrationFile = "./EEGLearningAccuracy";

	FILE* fResults = fopen(calibrationFile.c_str(), "a");

	fprintf(fResults, "%d\t%d\t%d\t%d\t%d\t%d\t%d\t%d\t%f\t%f\t%d\t%d\t\n", nTruePositivesM1, nTruePositivesM2, nTruePositivesM3, nVolunters, maxNM, argvMaxLagRate, argvTimeES, argvFH, trainingSetPercentage, validationSetPercentage, expT, expV);

	fprintf(fResults, "\n");

	fclose(fResults);
	// =======================================================

	return 0;
}

